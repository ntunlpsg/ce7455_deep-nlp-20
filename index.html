<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Tasnim Mohiuddin">

  
  
  
    
  
  <meta name="description" content="">

  
  <link rel="alternate" hreflang="en-us" href="https://ntunlpsg.github.io/ce7455_deep-nlp-20/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/ce7455_deep-nlp-20/css/academic.min.35387d828cf63a93f82a2d63a578781f.css">

  

  
  
  

  
  <link rel="alternate" href="/ce7455_deep-nlp-20/index.xml" type="application/rss+xml" title="DEEP-NLP">
  

  <link rel="manifest" href="/ce7455_deep-nlp-20/site.webmanifest">
  <link rel="icon" type="image/png" href="/ce7455_deep-nlp-20/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/ce7455_deep-nlp-20/img/icon-192.png">

  <link rel="canonical" href="https://ntunlpsg.github.io/ce7455_deep-nlp-20/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="DEEP-NLP">
  <meta property="og:url" content="https://ntunlpsg.github.io/ce7455_deep-nlp-20/">
  <meta property="og:title" content="DEEP-NLP">
  <meta property="og:description" content=""><meta property="og:image" content="https://ntunlpsg.github.io/ce7455_deep-nlp-20/img/icon-192.png">
  <meta property="twitter:image" content="https://ntunlpsg.github.io/ce7455_deep-nlp-20/img/icon-192.png"><meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2030-06-01T13:00:00&#43;00:00">
  

  


  





  <title>DEEP-NLP</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/ce7455_deep-nlp-20/">DEEP-NLP</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/ce7455_deep-nlp-20/#slider" data-target="#slider"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/ce7455_deep-nlp-20/#people" data-target="#people"><span>People</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/ce7455_deep-nlp-20/#schedule" data-target="#schedule"><span>Schedule & Course Content</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="https://ntulearn.ntu.edu.sg" target="_blank" rel="noopener"><span>NTU-learn</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  


<span class="js-widget-page d-none"></span>




  







  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  
    
    
    
  

  <section id="slider" class="home-section wg-slider    carousel slide"  data-ride="carousel" data-interval="false">
    
      




<ol class="carousel-indicators">
  
  <li data-target="#slider" data-slide-to="0" class="active"></li>
  
  <li data-target="#slider" data-slide-to="1" ></li>
  
</ol>


<div class="carousel-inner">
  
  <div class="wg-hero dark carousel-item active" style="
    
    background-color: #2b94c3;
    
    
    ;">
    <div class="container" style="text-align: center;">
        <h1 class="hero-title" itemprop="headline">
          CE7455: Deep Learning for Natural LanguageProcessing: From Theory to Practice
        </h1>

        

        
      </div>
  </div>
  
  <div class="wg-hero dark carousel-item" style="
    
    background-color: #2b94c3;
    
    
    ;">
    <div class="container" style="text-align: left;">
        <h1 class="hero-title" itemprop="headline">
          NTU-NLP
        </h1>

        
        <p class="hero-lead" style="">
          Natural Langauge Processing lab of NTU.
        </p>
        

        
        
        
        
          
        
        <p>
          <a href="https://ntunlpsg.github.io" class="btn btn-light btn-lg"><i class="fas fa-bullseye" style="padding-right: 10px;"></i>NTU-NLP</a>
        </p>
        
      </div>
  </div>
  
</div>


<a class="carousel-control-prev" href="#slider" data-slide="prev">
  <span class="carousel-control-prev-icon"></span>
  <span class="sr-only">Previous</span>
</a>
<a class="carousel-control-next" href="#slider" data-slide="next">
  <span class="carousel-control-next-icon"></span>
  <span class="sr-only">Next</span>
</a>

    
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="description" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 col-lg-12 section-heading">
      <h1>Course Objectives</h1>
      
    </div>
    <div class="col-12 col-lg-12">
      <p>Natural Language Processing (NLP) is one of the most important fields in Artificial Intelligence (AI). It has become very crucial in the information age because most of the information is in the form of unstructured text. NLP technologies are applied everywhere as people communicate mostly in language: language translation, web search, customer support, emails, forums, advertisement, radiology reports, to name a few.</p>

<p>There are a number of core NLP tasks and machine learning models behind NLP applications. Deep learning, a sub-field of machine learning, has recently brought a paradigm shift from traditional task-specific feature engineering to end-to-end systems and has obtained high performance across many different NLP tasks and downstream applications. Tech companies like Google, Baidu, Alibaba, Apple, Amazon, Facebook, Tencent, and Microsoft are now actively working on deep learning methods to improve their products. For example, Google recently replaced its traditional statistical machine translation and speech-recognition systems with systems based on deep learning methods.</p>

<p><strong>Optional Textbooks</strong></p>

<ul>
<li>Deep Learning by Goodfellow, Bengio, and Courville <a href="http://www.deeplearningbook.org/" target="_blank">free online</a></li>
<li>Machine Learning — A Probabilistic Perspective by Kevin Murphy <a href="https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf" target="_blank">online</a></li>
<li>Natural Language Processing by Jacob Eisenstein <a href="https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf" target="_blank">free online</a></li>
<li>Speech and Language Processing by Dan Jurafsky and James H. Martin <a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank">(3rd ed. draft)</a></li>
</ul>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="learning_outcome" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 col-lg-12 section-heading">
      <h1>Intended Learning Outcomes</h1>
      
    </div>
    <div class="col-12 col-lg-12">
      <p>In this course, students will learn state-of-the-art deep learning methods for NLP. Through lectures and practical assignments, students will learn the necessary tricks for making their models work on practical problems. They will learn to implement, and possibly to invent their own deep learning models using available deep learning libraries like <a href="https://pytorch.org/" target="_blank">Pytorch</a>.</p>

<p><strong>Our Approach</strong></p>

<ul>
<li><p><em>Thorough and Detailed</em>: How to write from scratch, debug and train deep neural models</p></li>

<li><p><em>State of the art</em>: Most lecture materials are new from research world in the past 1-5 years.</p></li>

<li><p><em>Practical</em>: Focus on practical techniques for training the models, and on GPUs.</p></li>

<li><p><em>Fun</em>: Cover exciting new advancements in NLP (e.g., Transformer, BERT).</p></li>
</ul>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="assessment" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 col-lg-12 section-heading">
      <h1>Assessment Approach</h1>
      
    </div>
    <div class="col-12 col-lg-12">
      <p><strong>Weekly Workload</strong></p>

<ul>
<li>Every two-hour lecture will be accompanied by practice problems implemented in PyTorch.</li>
<li>There will be a 30-min office hour per week to discuss assignments and project.</li>
<li>There will be <code>5%</code> marks for class participation.</li>
</ul>

<p><strong>Assignments (individually graded)</strong></p>

<ul>
<li>There will be three (3) assignments contributing to <code>3 * 15% = 45%</code> of the total assessment.</li>
<li>Late day policy

<ul>
<li>2 free late days; afterwards,<code>10%</code> off per day late</li>
<li>Not accepted after 3 late days</li>
</ul></li>
<li>Students will be graded individually on the assignments. They will be allowed to discuss with each other on the homework assignments, but they are required to submit individual write-ups and coding exercises.</li>
</ul>

<p><strong>Final Project (Group work but individually graded)</strong></p>

<ul>
<li>There will be a final project contributing to the remaining 50% of the total course-work assessment.

<ul>
<li><code>1–3</code> people per group</li>
<li>Project proposal: <code>5%</code>, update: <code>5%</code>, presentation: <code>10%</code>, report: <code>30%</code></li>
</ul></li>
<li>The project will be a group or individual work depending on the student’s preference. Students will be graded individually. The final project presentation will ensure the student’s understanding of the project</li>
</ul>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="prerequisites" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 col-lg-12 section-heading">
      <h1>Course Prerequisites</h1>
      
    </div>
    <div class="col-12 col-lg-12">
      <ul>
<li>Proficiency in Python (using numpy and PyTorch). There is a lecture for those who are not familiar with Python.</li>
<li>College Calculus, Linear Algebra</li>
<li>Basic Probability and Statistics</li>
<li>Machine Learning basics</li>
</ul>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="people" class="home-section wg-people   "  >
    <div class="container">
      


<div class="row justify-content-center people-widget">
  
  <div class="col-md-12 section-heading">
    <h1>Teaching</h1>
    
  </div>
  

  
  <div class="col-md-12">
    <!-- user_groups = ["Instructors",
               "Teaching Assistants",
               "Grad Students",
               "Administration",
               "Visitors",
               "Alumni"] -->

  </div>
  

  
  <div class="col-md-12">
    <h2 class="mb-4">Instructor</h2>
  </div>

  
  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/ce7455_deep-nlp-20/authors/joty/"><img class="portrait" src="/ce7455_deep-nlp-20/authors/joty/avatar_hubfcdeed5ceecb3a359cf69d9762e4d43_320707_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/ce7455_deep-nlp-20/authors/joty/">Shafiq Rayhan Joty</a></h2>
      
      
    </div>
  </div>

  
  
  <div class="col-md-12">
    <h2 class="mb-4">Teaching Assistants</h2>
  </div>

  
  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/ce7455_deep-nlp-20/authors/1.tasnim/"><img class="portrait" src="/ce7455_deep-nlp-20/authors/1.tasnim/avatar_huf89954896e995366ad07cd44579e7559_10908_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/ce7455_deep-nlp-20/authors/1.tasnim/">Tasnim Mohiuddin</a></h2>
      
      
    </div>
  </div>

  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/ce7455_deep-nlp-20/authors/2.tung/"><img class="portrait" src="/ce7455_deep-nlp-20/authors/2.tung/avatar_hu5e1b57f6aee3e99a37232699e9dc7057_9651_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/ce7455_deep-nlp-20/authors/2.tung/">Nguyen Thanh Tung</a></h2>
      
      
    </div>
  </div>

  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/ce7455_deep-nlp-20/authors/5.phi/"><img class="portrait" src="/ce7455_deep-nlp-20/authors/5.phi/avatar_hu4237dd9adc8f12e9c81cbe9c869c32b9_12128_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/ce7455_deep-nlp-20/authors/5.phi/">Xuan Phi Nguyen</a></h2>
      
      
    </div>
  </div>

  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/ce7455_deep-nlp-20/authors/7.-hancheol-moon/"><img class="portrait" src="/ce7455_deep-nlp-20/authors/7.-hancheol-moon/avatar_hub72ce5f3e9e18b80a9c579ea93c562a8_1508991_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/ce7455_deep-nlp-20/authors/7.-hancheol-moon/">Hancheol Moon</a></h2>
      
      
    </div>
  </div>

  

  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      <a href="/ce7455_deep-nlp-20/authors/8.-lin/"><img class="portrait" src="/ce7455_deep-nlp-20/authors/8.-lin/avatar_hu14a6cca5310ec3ee2cf48c5599d259e2_92286_150x150_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/ce7455_deep-nlp-20/authors/8.-lin/">Lin Xiang</a></h2>
      
      
    </div>
  </div>

  
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="schedule" class="home-section wg-experience   "  >
    <div class="container">
      



<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Schedule &amp; Course Content</h1>
    
  </div>
  <div class="col-12 col-lg-12">
    <!--       
  
  **Lecture Content (Shafiq, Tasnim, Lix Xiang)**


 <br>
  <br>
  """ -->


    
    
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col ">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 13: In-class Project presentation</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              15 April 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><ul>
<li>Project presentation: 15 min/group</li>
</ul></div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 12: Semisupervised Learning II &ndash; Adversarial Learning</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              8 April 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p>[Lecture Slide]</p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>Generative adversarial nets (GANs)</li>
<li>Domain adversarial nets (DANs)</li>
<li>Transfer learning with DANs</li>
<li>Training with adversarial examples</li>
<li>Consistency regularization</li>
<li>Cross-view consistency</li>

<li><p>Limits &amp; Future of Deep NLP</p>

<ul>
<li>Multi-sentence processing</li>
<li>Multi-task learning</li>
<li>Multimodal learning</li>
<li>Model interpretability


<br /></li>
</ul></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 11: Semisupervised Learning I &ndash; Self-supervised learning</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              1 April 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/y0c9h0jhpd76le0/Lecture-11.pdf?dl=0" target="_blank">Lecture Slide (partial)</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>Why semi-supervsied?</li>
<li>Semisupervised learning dimensions</li>

<li><p>Pre-training and fine-tuning methods</p>

<ul>
<li>ELMo</li>
<li>GPT</li>
<li>BERT</li>
<li>XLM</li>
<li>XL-Net</li>
</ul></li>

<li><p>Evaluation benchmarks</p>

<ul>
<li>GLUE</li>
<li>SQuAD</li>
</ul></li>
</ul>

<p><strong>Assignment <code>3</code> in</strong></p>

<p><strong>Practical exercise with Pytorch</strong></p>

<ul>
<li>Unsupervised Translation</li>
<li>Cross-lingual NER</li>
</ul>

<p><strong>[Supplementary reading] Variational Methods for Deep NLP</strong></p>

<ul>
<li>Deep learning meets graphical models</li>
<li>Variational autoencoders</li>
<li>Variational Generative adversarial nets (GANs)</li>
<li>Applications

<br /></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 10: Seq2Seq Variants and Transformer</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              25 March 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/ocitt0t1wyn7iwv/Lecture-10.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><a href="https://drive.google.com/file/d/1SlQXHQX_jJvTujfDZIzl3CQAeGiWZSK_/view?usp=sharing" target="_blank">Lecture Recording</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li><p>Seq2Seq Variants (Pointer nets, Pointer Generator Nets)</p>

<ul>
<li>Machine Translation</li>
<li>Summarization</li>
<li>Parsing</li>
<li>image/video captioning</li>
</ul></li>

<li><p>Transformer architecture</p>

<ul>
<li>Self-attention</li>
<li>Positional encoding</li>
<li>Multi-head attention</li>
</ul></li>
</ul>

<p><strong>Invited talk on Tree-transformer</strong></p>

<ul>
<li><a href="https://openreview.net/pdf?id=HJxK5pEYvr" target="_blank">Xuan-Phi on Tree-transformer</a></li>
</ul>

<p><strong>Suggested Readings</strong></p>

<ul>
<li><p><a href="https://arxiv.org/abs/1704.04368" target="_blank">Get To The Point: Summarization with Pointer-Generator Networks</a></p></li>

<li><p><a href="https://papers.nips.cc/paper/5866-pointer-networks" target="_blank">Pointer Networks</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/P18-1130.pdf" target="_blank">Stack-Pointer Networks for Dependency Parsing</a></p></li>

<li><p><a href="https://arxiv.org/abs/1905.05682" target="_blank">A Unified Linear-Time Framework for Sentence-Level Discourse Parsing</a></p></li>

<li><p><a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention Is All You Need</a></p></li>

<li><p><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank">The Illustrated Transformer</a></p></li>

<li><p><a href="https://arxiv.org/abs/1911.03014" target="_blank">Resurrecting Submodularity in Neural Abstractive Summarization</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 9: Seq2Seg Models with Attentions</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              18 March 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/1w14l10ggyir2yl/Lecture-9.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><a href="https://drive.google.com/open?id=1pZF0D1Qw_AxCLLOdelwtjv0XXC8UkGrW" target="_blank">Lecture Recording</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>Information bottleneck issue with vanilla Seq2Seq</li>
<li>Attention to the rescue</li>
<li>Details of attention mechanism</li>
<li>Attention variants</li>
<li>Unsupervised MT</li>
<li>Discourse level MT</li>
</ul>

<p><strong>Assignment <code>3</code> out</strong></p>

<p><strong>Suggested Readings</strong></p>

<ul>
<li><p><a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank">Neural Machine Translation by Jointly Learning to Align and Translate (original seq2seq+attention paper)</a></p></li>

<li><p><a href="https://nlp.stanford.edu/~lmthang/data/papers/emnlp15_attn.pdf" target="_blank">Effective Approaches to Attention-based Neural Machine Translation</a></p></li>

<li><p><a href="https://arxiv.org/abs/1604.00788" target="_blank">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></p></li>

<li><p><a href="https://arxiv.org/abs/1711.00043" target="_blank">Unsupervised Machine Translation Using Monolingual Corpora Only</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/D18-1549.pdf" target="_blank">Phrase-Based &amp; Neural Unsupervised Machine Translation</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 8: Machine translation and Seq2Seg Models</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              11 March 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/nxupgcyj158xm95/Lecture-8.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><a href="https://drive.google.com/open?id=1NoP6CJy7OrnVsvhR-5oJxda9E6NoAMB1" target="_blank">Video Lecture</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li><p>Machine translation</p>

<ul>
<li>Early days (1950s)</li>
<li>Statistical machine translation or SMT (1990-2010)</li>
<li>Alignment in SMT</li>
<li>Decoding in SMT</li>
</ul></li>

<li><p>Neural machine translation or NMT (2014 - )</p></li>

<li><p>Encoder-decoder model for NMT</p></li>

<li><p>Advantages and disadvantages of NMT</p></li>

<li><p>Greedy vs. beam-search decoding</p></li>

<li><p>Byte-pair encoding</p></li>

<li><p>MT evaluation</p></li>

<li><p>Other applications of Seq2Seq</p></li>
</ul>

<p><strong>Practical exercise with Pytorch</strong></p>

<ul>
<li><a href="https://colab.research.google.com/drive/1cYyBxmdjFjKls0CEsPc8WIHfxPDy4eSq" target="_blank">Neural machine translation tutorial in pytorch</a></li>
</ul>

<p><strong>Suggested Readings</strong></p>

<ul>
<li><p><a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/syllabus.shtml" target="_blank">Statistical Machine Translation slides, CS224n 2015 (lectures 2/3/4)</a></p></li>

<li><p><a href="https://arxiv.org/pdf/1409.3215.pdf" target="_blank">Sequence to Sequence Learning with Neural Networks (original seq2seq NMT paper)</a></p></li>

<li><p><a href="https://www.cambridge.org/core/books/statistical-machine-translation/94EADF9F680558E13BE759997553CDE5" target="_blank">Statistical Machine Translation (book by Philipp Koehn)</a></p></li>

<li><p><a href="https://arxiv.org/abs/1506.05869" target="_blank">A Neural Conversational Model</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank">BLEU (original paper)</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Recess Week</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              4 March 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><strong><code>No</code> Lecture</strong></p>

<p><strong>Assignment <code>2</code> in</strong></p>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 7: Recursive Neural Nets &amp; Parsing</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              26 February 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://ntulearn.ntu.edu.sg/" target="_blank">Project Proposal Instructions in NTU Learn (inside Content)</a></p>

<p><a href="https://www.dropbox.com/s/baefzxldyv54m3l/Lecture-7.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><a href="https://drive.google.com/file/d/1GMz_1ac4oI-FquGj5WnO_WL3pG_6P9OK/view?usp=sharing" target="_blank">Video Lecture - Part 1</a></p>

<p><a href="https://drive.google.com/file/d/1XRMIAe3TKl0UftF-34-qJvHd8xk-C_5h/view?usp=sharing" target="_blank">Video Lecture - Part 2</a></p>

<p><code>Project Proposal due</code></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>Compositionality in language &amp; recursion</li>
<li>Recursive vs. recurrent NN</li>
<li>Parsing with tree-structured recursive NN</li>
<li>Tree LSTMs</li>
<li>Backpropagation through tree</li>

<li><p>Other applications of recursive NN</p>

<ul>
<li>Fine-grained sentiment analysis</li>
<li>Semantic relationship identification</li>
</ul></li>

<li><p>Modern parsers</p></li>
</ul>

<p><strong>Practical exercise with Pytorch</strong></p>

<ul>
<li>Sentiment treebank</li>
<li>Subject-Verb Agreement</li>
</ul>

<p><strong>Suggested Readings</strong></p>

<ul>
<li><p><a href="https://www.aclweb.org/anthology/P13-1045/" target="_blank">Parsing with Compositional Vector Grammars</a></p></li>

<li><p><a href="https://arxiv.org/pdf/1805.01052.pdf" target="_blank">Constituency Parsing with a Self-Attentive Encoder</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/P17-1076/" target="_blank">A Minimal Span-Based Neural Constituency Parser</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/N16-1024/" target="_blank">Recurrent Neural Network Grammars</a></p></li>

<li><p><a href="http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf" target="_blank">Grammar as a Foreign Language</a></p></li>

<li><p><a href="https://arxiv.org/abs/1804.07853" target="_blank">What&rsquo;s Going On in Neural Constituency Parsers? An Analysis</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 6: Recurrent Neural Nets</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              19 February 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/18dheidnf0msoie/Lecture-6.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><a href="https://drive.google.com/file/d/1vLYK4Lp-doHALhdlTVzthGiM5Vn-Vwhz/view?usp=sharing" target="_blank">Video Lecture - Part 1</a></p>

<p><a href="https://drive.google.com/file/d/1WBmK1ELWQYf_mYq7pQZW2Tjxlsr56L34/view?usp=sharing" target="_blank">Video Lecture - Part 2</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>Basic RNN structures</li>
<li>Language modeling with RNNs</li>
<li>Backpropagation through time</li>
<li>Text generation with RNN LM</li>
<li>Issues with Vanilla RNNs</li>
<li>Exploding gradient</li>
<li>Gated Recurrent Units (GRUs) and LSTMs</li>
<li>Bidirectional RNNs</li>
<li>Multi-layer RNNs</li>
<li>Sequence labeling with RNNs</li>
<li>Sequence classification with RNNs</li>
</ul>

<p><strong>Assignment <code>2</code> out</strong></p>

<p><strong>Practical exercise with Pytorch</strong></p>

<ul>
<li><a href="https://github.com/jayavardhanr/End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/blob/master/Named_Entity_Recognition-LSTM-CNN-CRF-Tutorial.ipynb" target="_blank">Named Entity Recognition</a></li>
</ul>

<p><strong>Suggested Readings</strong></p>

<ul>
<li><p><a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf" target="_blank">N-gram Language Models</a></p></li>

<li><p><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank">Karpathy&rsquo;s nice blog on Recurrent Neural Networks</a></p></li>

<li><p><a href="https://research.fb.com/building-an-efficient-neural-language-model-over-a-billion-words/" target="_blank">Building an Efficient Neural Language Model</a></p></li>

<li><p><a href="http://proceedings.mlr.press/v28/pascanu13.pdf" target="_blank">On the difficulty of training recurrent neural networks</a></p></li>

<li><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank">Colah&rsquo;s blog on LSTMs/GRUs</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/N16-1030/" target="_blank">Neural Architectures for Named Entity Recognition</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/D15-1168/" target="_blank">Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings</a></p></li>

<li><p><a href="https://arxiv.org/abs/1911.09812" target="_blank">Zero-Resource Cross-Lingual NER</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 5: Cross-lingual Word Vectors &amp; CNNs</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              12 February 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/at3wztn2dn7h2k2/Lecture-5.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><a href="https://drive.google.com/open?id=18hsT0Pm3yGGliCCmoapW7XenEIEzP51L" target="_blank">Slides with recording</a></p>

<p><a href="https://drive.google.com/file/d/1PU-8asYE4LdfBRbKa-CPD-b2gip0k7pQ/view?usp=sharing" target="_blank">Slides with video</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>Cross-lingual word embeddings<br /></li>
<li>Classification tasks in NLP</li>
<li>Window-based Approach for language modeling</li>
<li>Window-based Approach for NER, POS tagging, and Chunking</li>
<li>Convolutional Neural Net for NLP</li>
<li>Max-margin Training</li>
<li>Scaling Softmax (Adaptive input &amp; output)</li>
</ul>

<p><strong>Assignment <code>1</code> in</strong></p>

<p><strong>Invited talk on cross-lingual word vectors</strong></p>

<ul>
<li><a href="https://taasnim.github.io/" target="_blank">Tasnim Modiuddin</a></li>
<li><a href="https://www.dropbox.com/s/al987q6ltv3zpfv/word-tr-Tasnim.pdf?dl=0" target="_blank">Talk Slides</a></li>
</ul>

<p><strong>Practical exercise with Pytorch</strong></p>

<ul>
<li><a href="https://github.com/FengZiYjun/CharLM" target="_blank">CNN for word encoding</a></li>
</ul>

<p><strong>Suggested Readings</strong></p>

<ul>
<li><p><a href="http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf" target="_blank">Natural Language Processing (Almost) from Scratch</a></p></li>

<li><p><a href="https://arxiv.org/abs/1408.5882" target="_blank">Convolutional Neural Networks for Sentence Classification</a></p></li>

<li><p><a href="https://arxiv.org/abs/1508.06615" target="_blank">Character-Aware Neural Language Models</a></p></li>

<li><p><a href="https://arxiv.org/abs/1702.02098" target="_blank">Fast and Accurate Entity Recognition with Iterated Dilated Convolutions</a></p></li>

<li><p><a href="https://arxiv.org/abs/1609.04309" target="_blank">Adaptive Softmax Paper</a></p></li>

<li><p><a href="https://openreview.net/pdf?id=ByxZX20qFQ" target="_blank">Adaptive Input representation paper</a></p></li>

<li><p><a href="https://openreview.net/forum?id=HklBjCEKvH" target="_blank">KNN-LM paper</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 4: Word Vectors</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              5 February 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/2m8pyvjfs5m6zpd/Lecture-4.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>Word meaning</li>
<li>Denotational semantics</li>
<li>Distributed representation of words</li>
<li>Word2Vec models (Skip-gram, CBOW)</li>
<li>Negative sampling</li>
<li>Glove</li>
<li>FastText</li>

<li><p>Evaluating word vectors</p>

<ul>
<li>Intrinsic evaluation</li>
<li>Extrinsic evaluation</li>
</ul></li>

<li><p>Cross-lingual word vectors</p></li>
</ul>

<p><strong>Practical exercise with Pytorch</strong></p>

<ul>
<li><p><a href="https://colab.research.google.com/drive/164dB-Vemzwavf1ffqDDVNtx7Y5VtcmQh" target="_blank">Skip-gram training</a></p></li>

<li><p>Visualization</p></li>
</ul>

<p><strong>Suggested Readings</strong></p>

<ul>
<li>Word2Vec Tutorial - The Skip-Gram Model <a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" target="_blank">blog</a></li>
<li><a href="https://arxiv.org/abs/1301.3781" target="_blank">Efficient Estimation of Word Representations in Vector Space</a> - Original word2vec paper</li>
<li><a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank">Distributed Representations of Words and Phrases and their Compositionality</a> - negative sampling paper</li>
<li><a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank">GloVe: Global Vectors for Word Representation</a></li>
<li><a href="https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00051?mobileUi=0" target="_blank">FastText: Enriching Word Vectors with Subword Information</a></li>
<li><a href="https://levyomer.files.wordpress.com/2014/04/linguistic-regularities-in-sparse-and-explicit-word-representations-conll-2014.pdf" target="_blank">Linguistic Regularities in Sparse and Explicit Word Representations.</a></li>
<li><a href="https://levyomer.files.wordpress.com/2014/09/neural-word-embeddings-as-implicit-matrix-factorization.pdf" target="_blank">Neural Word Embeddings as Implicit Matrix Factorization.</a></li>

<li><p><a href="https://www.aclweb.org/anthology/Q15-1016/" target="_blank">Improving Distributional Similarity with Lessons Learned from Word Embeddings</a></p></li>

<li><p><a href="https://arxiv.org/abs/1706.04902" target="_blank">Survey on Cross-lingual embedding methods</a></p></li>

<li><p><a href="https://www.dropbox.com/s/3eq5apr75yrz9ix/Cross-lingual%20word%20embeddings%20and%20beyond.pdf?dl=0" target="_blank">Slides on Cross-lingual embedding</a></p></li>

<li><p><a href="https://arxiv.org/abs/1904.04116" target="_blank">Adversarial autoencoder for unsupervised word translation</a></p></li>

<li><p><a href="https://www.aclweb.org/anthology/P19-1070" target="_blank">Evaluating Cross-Lingual Word Embeddings</a></p></li>

<li><p><a href="https://transacl.org/ojs/index.php/tacl/article/viewFile/1346/320" target="_blank">Linear Algebraic Structure of Word Senses, with Applications to Polysemy</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 3: Neural Network &amp; Optimization Basics</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              29 January 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/bqlf5kmvr2mcyjd/Lecture-3.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li><p>Why Deep Learning for NLP?</p></li>

<li><p>From Logistic Regression to Feed-forward NN</p>

<ul>
<li>Activation functions</li>
</ul></li>

<li><p>SGD with Backpropagation</p></li>

<li><p>Adaptive SGD (Adagrad, adam, RMSProp)</p></li>

<li><p>Regularization (Weight Decay, Dropout, Batch normalization, Gradient clipping)</p></li>

<li><p>Introduction to Word Vectors</p></li>
</ul>

<p><strong>Assignment <code>1</code> out</strong></p>

<p><strong>Practical exercise with Pytorch</strong></p>

<p><a href="https://colab.research.google.com/drive/1IAonxZnZjJb0_xUVWHt5atIxaI5GTJQ2" target="_blank">Numpy notebook</a> <a href="https://colab.research.google.com/drive/1YzZrMAmJ3hjvJfNIdGxae9kxGABG6yaT" target="_blank">Pytorch notebook</a></p>

<ul>
<li>Backpropagation</li>
<li>Dropout</li>
<li>Batch normalization</li>
<li>Initialization</li>
<li>Gradient clipping</li>
</ul>

<p><strong>Suggested Readings</strong></p>

<ul>
<li><p>SGD optimization <a href="https://ruder.io/optimizing-gradient-descent/" target="_blank">blog</a></p></li>

<li><p><a href="https://arxiv.org/abs/1609.04747" target="_blank">An overview of gradient descent optimization algorithms</a></p></li>

<li><p><a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank">Adam: a Method for Stochastic Optimization</a></p></li>

<li><p><a href="http://proceedings.mlr.press/v70/bello17a.html" target="_blank">Neural Optimizer Search with Reinforcement Learning</a></p></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 2: Machine Learning Basics</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              22 January 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/hzizorgpwsbgi58/Lecture-2.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>What is Machine Learning?</li>
<li>Supervised vs. unsupervised learning</li>
<li>Linear Regression</li>
<li>Logistic Regression</li>
<li>Multi-class classification</li>
<li>Parameter estimation (MLE &amp; MAP)</li>
<li>Gradient-based optimization &amp; SGD</li>
</ul>

<p><strong>Practical exercise with Pytorch</strong></p>

<ul>
<li><a href="https://colab.research.google.com/drive/1tRayE1KjvmENZJe9oGwtnRNw_sbrwb5d" target="_blank">Deep learning with PyTorch</a></li>
<li><a href="https://colab.research.google.com/drive/1krekWlJPHjvxH6fMzjYohR-1OX43bp67" target="_blank">Linear Regression</a></li>

<li><p><a href="https://colab.research.google.com/drive/1rpvMmkYgU3LWnmsG7xaowDhAdJCWFzOU" target="_blank">Logistic Regression</a></p></li>

<li><p>[Supplementary]</p>

<ul>
<li>Numerical programming with Pytorch - <a href="https://drive.google.com/file/d/18cgPOj2QKQN0WR9_vXoz6BoravvS9mTm/view?usp=sharing" target="_blank">Pytorch intro</a>
<br /></li>
</ul></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border exp-fill">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Week 1: Introduction</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
                <span>02:30 PM - 5:30 PM</span>
                <span class="middot-divider"></span>
              
              
              15 January 2020
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><p><a href="https://www.dropbox.com/s/3o9zo7yljht0g4b/Lecture-1.pdf?dl=0" target="_blank">Lecture Slide</a></p>

<p><strong>Lecture Content</strong></p>

<ul>
<li>What is Natural Language Processing?</li>
<li>Why is language understanding difficult?</li>
<li>What is Deep Learning?</li>
<li>Deep learning vs. other machine learning methods?</li>
<li>Why deep learning for NLP?</li>
<li>Applications of deep learning to NLP</li>
<li>Knowing the target group (background, field of study, programming experience)</li>
<li>Expectation from the course
<br /></li>
</ul>

<p><strong>Python &amp; PyTorch Basics</strong></p>

<ul>
<li><p>Programming in Python</p>

<ul>
<li>Jupiter Notebook and <a href="https://colab.research.google.com/drive/16pBJQePbqkz3QFV54L4NIkOn1kwpuRrj" target="_blank">google colab</a></li>
<li><a href="https://colab.research.google.com/drive/1bQG32CFoMZ-jBk02uaFon60tER3yFx4c" target="_blank">Introduction to python</a></li>
<li>Deep Learning Frameworks</li>
<li>Why Pytorch?</li>
<li><a href="https://drive.google.com/file/d/1c33y8bkdr7SJ_I8-wmqTAhld-y7KcspA/view?usp=sharing" target="_blank">Deep learning with PyTorch</a></li>
</ul></li>

<li><p>[Supplementary]</p>

<ul>
<li>Numerical programming with numpy/scipy - <a href="https://drive.google.com/file/d/1cUzRzQGURrCKes8XynvTTA4Zvl_gUJdc/view?usp=sharing" target="_blank">Numpy intro</a></li>
<li>Numerical programming with Pytorch - <a href="https://drive.google.com/file/d/18cgPOj2QKQN0WR9_vXoz6BoravvS9mTm/view?usp=sharing" target="_blank">Pytorch intro</a>


<br /></li>
</ul></li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    <div class="row experience">
      
      <div class="col-auto text-center flex-column d-none d-sm-flex">
        <div class="row h-50">
          <div class="col border-right">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
        <div class="m-2">
          <span class="badge badge-pill border ">&nbsp;</span>
        </div>
        <div class="row h-50">
          <div class="col ">&nbsp;</div>
          <div class="col">&nbsp;</div>
        </div>
      </div>
      
      <div class="col py-2">
        <div class="card">
          <div class="card-body">
            <h4 class="card-title exp-title text-muted mt-0 mb-1">Futher Reading: Deep Reinforcement Learning for NLP</h4>
            <h4 class="card-title exp-company text-muted my-0"></h4>
            <div class="text-muted exp-meta">
              
              
              1 January 2019
              
              
                <span class="middot-divider"></span>
                <span>LT13, NTU, Singapore </span>
              
              
            </div>
            <div class="card-text"><ul>
<li>What is RL?</li>
<li>Key concepts: Rewards, Policy, Value Function</li>
<li>What is Deep RL?</li>

<li><p>Policy-based Deep RL</p>

<ul>
<li>Deep Policy Network</li>
<li>Policy Gradient</li>
</ul></li>

<li><p>Deep Q-Learning</p></li>

<li><p>Applications of Deep RL in NLP</p>

<ul>
<li>Abstractive summarization</li>
<li>Dialogue generation</li>
<li>Question answering</li>
<li>Multimodal (image and video captioning)</li>
<li>Machine translation</li>
</ul></li>
</ul>

<p><strong>[Supplementary reading] Variational Methods for Deep NLP</strong></p>

<ul>
<li>Deep learning meets graphical models</li>
<li>Variational autoencoders</li>
<li>Variational Generative adversarial nets (GANs)</li>
<li>Applications</li>
</ul>
</div>
          </div>
        </div>
      </div>
    </div>
    
    
  </div>
</div>

    </div>
  </section>



      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/ce7455_deep-nlp-20/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/ce7455_deep-nlp-20/js/academic.min.9881d84a7dbd704179a08d7d1d079225.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
